{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "import hdbscan\n",
    "\n",
    "import umap\n",
    "\n",
    "from  itertools import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'boston', \n",
    "    'breastcancercoimbra',\n",
    "    'breastcancerwisconsinprognostic',\n",
    "    'covertype',\n",
    "    'dermatology',\n",
    "    'drybean',\n",
    "    'echocardiogram',\n",
    "    'ecoli',\n",
    "    'extyaleb',\n",
    "    'glassidentification',\n",
    "    'heartdisease',\n",
    "    'hepatitis',\n",
    "    'housing', 'iris', 'mnist64', 'olive', 'weather', 'wine', 'world12d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0503 Metric binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[['DTM_KL01', 'Trustworthiness','Cohesiveness' ]].to_json('./metric_some.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>DTM_KL1</th>\n",
       "      <th>DTM_KL01</th>\n",
       "      <th>DTM_KL001</th>\n",
       "      <th>Sammon</th>\n",
       "      <th>Trustworthiness</th>\n",
       "      <th>Continuity</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Steadiness</th>\n",
       "      <th>Cohesiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>world12d_0</th>\n",
       "      <td>3953.422363</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.053075</td>\n",
       "      <td>0.918514</td>\n",
       "      <td>0.964815</td>\n",
       "      <td>0.991759</td>\n",
       "      <td>0.807931</td>\n",
       "      <td>0.947093</td>\n",
       "      <td>0.913462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_1</th>\n",
       "      <td>3960.921143</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>0.059423</td>\n",
       "      <td>0.935628</td>\n",
       "      <td>0.959149</td>\n",
       "      <td>0.990833</td>\n",
       "      <td>0.767015</td>\n",
       "      <td>0.949786</td>\n",
       "      <td>0.909584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_2</th>\n",
       "      <td>3965.792969</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.021634</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.949452</td>\n",
       "      <td>0.959636</td>\n",
       "      <td>0.990171</td>\n",
       "      <td>0.751908</td>\n",
       "      <td>0.915189</td>\n",
       "      <td>0.893664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_3</th>\n",
       "      <td>3963.496338</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.022761</td>\n",
       "      <td>0.063225</td>\n",
       "      <td>0.942423</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>0.990852</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.954423</td>\n",
       "      <td>0.892510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_4</th>\n",
       "      <td>3958.509766</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.061063</td>\n",
       "      <td>0.931516</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.992047</td>\n",
       "      <td>0.792585</td>\n",
       "      <td>0.947122</td>\n",
       "      <td>0.911067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RMSE   DTM_KL1  DTM_KL01  DTM_KL001    Sammon  \\\n",
       "world12d_0  3953.422363  0.003898  0.024877   0.053075  0.918514   \n",
       "world12d_1  3960.921143  0.004483  0.023187   0.059423  0.935628   \n",
       "world12d_2  3965.792969  0.004917  0.021634   0.060510  0.949452   \n",
       "world12d_3  3963.496338  0.004523  0.022761   0.063225  0.942423   \n",
       "world12d_4  3958.509766  0.004037  0.021537   0.061063  0.931516   \n",
       "\n",
       "            Trustworthiness  Continuity  Spearman  Steadiness  Cohesiveness  \n",
       "world12d_0         0.964815    0.991759  0.807931    0.947093      0.913462  \n",
       "world12d_1         0.959149    0.990833  0.767015    0.949786      0.909584  \n",
       "world12d_2         0.959636    0.990171  0.751908    0.915189      0.893664  \n",
       "world12d_3         0.955651    0.990852  0.769675    0.954423      0.892510  \n",
       "world12d_4         0.961658    0.992047  0.792585    0.947122      0.911067  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.read_json('./metric_all.json', orient='index')\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "z_value = pd.DataFrame(scalar.fit_transform(metrics), columns=metrics.columns, index=metrics.index).round(5)\n",
    "pval = pd.DataFrame(stats.norm.cdf(z_value), index=z_value.index, columns=z_value.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned = pd.DataFrame(index=metrics.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['Cohesiveness', 'Trustworthiness', 'DTM_KL01']\n",
    "for k in key:\n",
    "    binned[k] = pval[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "world12d_0    8\n",
       "world12d_1    8\n",
       "world12d_2    8\n",
       "world12d_3    8\n",
       "world12d_4    8\n",
       "             ..\n",
       "olive_65      2\n",
       "olive_66      1\n",
       "olive_67      1\n",
       "olive_68      0\n",
       "olive_69      1\n",
       "Name: T_bin, Length: 1310, dtype: category\n",
       "Categories (10, object): ['0' < '1' < '2' < '3' ... '6' < '7' < '8' < '9']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_pval['T_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trustworthiness</th>\n",
       "      <th>Cohesiveness</th>\n",
       "      <th>DTM_KL01</th>\n",
       "      <th>T_bin</th>\n",
       "      <th>C_bin</th>\n",
       "      <th>K_bin</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>world12d_0</th>\n",
       "      <td>0.625451</td>\n",
       "      <td>0.793279</td>\n",
       "      <td>0.492879</td>\n",
       "      <td>(0.56, 0.63]</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_1</th>\n",
       "      <td>0.612825</td>\n",
       "      <td>0.788628</td>\n",
       "      <td>0.483477</td>\n",
       "      <td>(0.56, 0.63]</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_2</th>\n",
       "      <td>0.613916</td>\n",
       "      <td>0.768900</td>\n",
       "      <td>0.474847</td>\n",
       "      <td>(0.56, 0.63]</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_3</th>\n",
       "      <td>0.604969</td>\n",
       "      <td>0.767430</td>\n",
       "      <td>0.481109</td>\n",
       "      <td>(0.56, 0.63]</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_4</th>\n",
       "      <td>0.618430</td>\n",
       "      <td>0.790414</td>\n",
       "      <td>0.474310</td>\n",
       "      <td>(0.56, 0.63]</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_65</th>\n",
       "      <td>0.210035</td>\n",
       "      <td>0.108945</td>\n",
       "      <td>0.593198</td>\n",
       "      <td>(0.14, 0.21]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_66</th>\n",
       "      <td>0.093184</td>\n",
       "      <td>0.050625</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>(0.07, 0.14]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_67</th>\n",
       "      <td>0.093184</td>\n",
       "      <td>0.047605</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>(0.07, 0.14]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_68</th>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.034833</td>\n",
       "      <td>0.442344</td>\n",
       "      <td>(-0.0007, 0.07]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_69</th>\n",
       "      <td>0.093184</td>\n",
       "      <td>0.047977</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>(0.07, 0.14]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Trustworthiness  Cohesiveness  DTM_KL01            T_bin C_bin  \\\n",
       "world12d_0         0.625451      0.793279  0.492879     (0.56, 0.63]     9   \n",
       "world12d_1         0.612825      0.788628  0.483477     (0.56, 0.63]     9   \n",
       "world12d_2         0.613916      0.768900  0.474847     (0.56, 0.63]     8   \n",
       "world12d_3         0.604969      0.767430  0.481109     (0.56, 0.63]     8   \n",
       "world12d_4         0.618430      0.790414  0.474310     (0.56, 0.63]     9   \n",
       "...                     ...           ...       ...              ...   ...   \n",
       "olive_65           0.210035      0.108945  0.593198     (0.14, 0.21]     1   \n",
       "olive_66           0.093184      0.050625  0.563496     (0.07, 0.14]     0   \n",
       "olive_67           0.093184      0.047605  0.563496     (0.07, 0.14]     0   \n",
       "olive_68           0.044295      0.034833  0.442344  (-0.0007, 0.07]     0   \n",
       "olive_69           0.093184      0.047977  0.563496     (0.07, 0.14]     0   \n",
       "\n",
       "           K_bin  bin  \n",
       "world12d_0     4  894  \n",
       "world12d_1     4  894  \n",
       "world12d_2     4  884  \n",
       "world12d_3     4  884  \n",
       "world12d_4     4  894  \n",
       "...          ...  ...  \n",
       "olive_65       5  215  \n",
       "olive_66       5  105  \n",
       "olive_67       5  105  \n",
       "olive_68       4  004  \n",
       "olive_69       5  105  \n",
       "\n",
       "[1310 rows x 7 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_pval[['bin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_pval['bin'] = binned_pval['T_bin'].astype(str) + binned_pval['C_bin'].astype(str) + binned_pval['K_bin'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlying</th>\n",
       "      <th>convex</th>\n",
       "      <th>skinny</th>\n",
       "      <th>skewed</th>\n",
       "      <th>clumpy</th>\n",
       "      <th>striated</th>\n",
       "      <th>sparse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>world12d_0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world12d_4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_65</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_66</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_67</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_68</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive_69</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           outlying convex skinny skewed clumpy striated sparse\n",
       "world12d_0    False   True  False  False  False    False   True\n",
       "world12d_1    False   True  False  False   True    False   True\n",
       "world12d_2    False   True  False  False   True     True   True\n",
       "world12d_3    False   True  False  False  False     True   True\n",
       "world12d_4    False   True  False  False   True     True   True\n",
       "...             ...    ...    ...    ...    ...      ...    ...\n",
       "olive_65       True   True  False   True  False    False  False\n",
       "olive_66       True  False   True   True  False     True  False\n",
       "olive_67       True  False   True   True  False     True  False\n",
       "olive_68       True  False   True   True   True     True  False\n",
       "olive_69       True  False   True   True  False     True  False\n",
       "\n",
       "[1310 rows x 7 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_bin = pd.DataFrame(columns=['outlying', 'convex', 'skinny', 'skewed', 'clumpy', 'striated',\n",
    "#        'sparse'], index=binned_pval.index)\n",
    "all_bin = pd.DataFrame(index=binned_pval.index)\n",
    "all_bin = all_bin.merge(binned_pval[['T_bin', 'C_bin', 'K_bin']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['outlying', 'convex', 'skinny', 'skewed', 'clumpy', 'striated',\n",
       "       'sparse', 'mdp', 'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scag = pd.read_json('./scag_bin.json')\n",
    "scag.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bin.to_json('./all_bin.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-343-0be979ec6476>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_bin.loc[m]['outlying'] = row.outlying\n",
      "<ipython-input-343-0be979ec6476>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_bin.loc[m]['convex'] = row.convex\n",
      "<ipython-input-343-0be979ec6476>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_bin.loc[m]['skinny'] = row.skinny\n",
      "<ipython-input-343-0be979ec6476>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_bin.loc[m]['skewed'] = row.skewed\n",
      "<ipython-input-343-0be979ec6476>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_bin.loc[m]['clumpy'] = row.clumpy\n",
      "<ipython-input-343-0be979ec6476>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_bin.loc[m]['striated'] = row.striated\n",
      "<ipython-input-343-0be979ec6476>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_bin.loc[m]['sparse'] = row['sparse']\n"
     ]
    }
   ],
   "source": [
    "for idx, row in scag.iterrows():\n",
    "    if (row.mdp):\n",
    "        for m in row.mdp.split('/')[:-1]:\n",
    "            all_bin.loc[m]['outlying'] = row.outlying\n",
    "            all_bin.loc[m]['convex'] = row.convex\n",
    "            all_bin.loc[m]['skinny'] = row.skinny\n",
    "            all_bin.loc[m]['skewed'] = row.skewed\n",
    "            all_bin.loc[m]['clumpy'] = row.clumpy\n",
    "            all_bin.loc[m]['striated'] = row.striated\n",
    "            all_bin.loc[m]['sparse'] = row['sparse']\n",
    "\n",
    "all_bin.to_json('./all_bin.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_pval.bin.value_counts().to_csv('./binned_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>K</th>\n",
       "      <th>bin</th>\n",
       "      <th>mdps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>glassidentification_65/glassidentification_66/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>004</td>\n",
       "      <td>breastcancerwisconsinprognostic_22/breastcance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>005</td>\n",
       "      <td>world12d_21/world12d_25/iris_23/breastcancerwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>006</td>\n",
       "      <td>world12d_20/ecoli_46/breastcancerwisconsinprog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>007</td>\n",
       "      <td>wine_20/wine_21/wine_22/wine_23/wine_24/boston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>994</td>\n",
       "      <td>world12d_26/world12d_34/iris_19/iris_33/breast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>995</td>\n",
       "      <td>world12d_28/world12d_29/world12d_32/weather_2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>996</td>\n",
       "      <td>world12d_10/world12d_13/weather_28/weather_33/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>997</td>\n",
       "      <td>weather_29/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>998</td>\n",
       "      <td>weather_26/weather_34/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T  C  K  bin                                               mdps\n",
       "0    0  0  0  000  glassidentification_65/glassidentification_66/...\n",
       "1    0  0  4  004  breastcancerwisconsinprognostic_22/breastcance...\n",
       "2    0  0  5  005  world12d_21/world12d_25/iris_23/breastcancerwi...\n",
       "3    0  0  6  006  world12d_20/ecoli_46/breastcancerwisconsinprog...\n",
       "4    0  0  7  007  wine_20/wine_21/wine_22/wine_23/wine_24/boston...\n",
       "..  .. .. ..  ...                                                ...\n",
       "219  9  9  4  994  world12d_26/world12d_34/iris_19/iris_33/breast...\n",
       "220  9  9  5  995  world12d_28/world12d_29/world12d_32/weather_2/...\n",
       "221  9  9  6  996  world12d_10/world12d_13/weather_28/weather_33/...\n",
       "222  9  9  7  997                                        weather_29/\n",
       "223  9  9  8  998                             weather_26/weather_34/\n",
       "\n",
       "[224 rows x 5 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['T', 'C', 'K', 'bin',  'mdps'])\n",
    "\n",
    "for bin, data in binned_pval.groupby(['T_bin', 'C_bin', 'K_bin', 'bin']):\n",
    "    str=\"\"\n",
    "    for i in data.index:\n",
    "        str += i + '/'\n",
    "    results = results.append({'T': bin[0], 'C': bin[1], 'K': bin[2], 'bin': bin[3], 'mdps': str}, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_json('./metric_binned.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.001,  0.086,  0.173,  0.259,  0.346,  0.432,  0.519,  0.605,\n",
       "        0.691,  0.778,  0.864])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_bins.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.254059056469189"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.norm.pdf(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_bins.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "(binned_pval['T_bin'], T_bins) = pd.cut(pval['Trustworthiness'], bins=10, retbins=True, labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "(binned_pval['C_bin'], C_bins) = pd.cut(pval['Cohesiveness'], bins=10, retbins=True, labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "(binned_pval['K_bin'], K_bins) = pd.cut(pval['DTM_KL01'], bins=10, retbins=True, labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(world12d_0    (0.4, 0.5]\n",
       " world12d_1    (0.4, 0.5]\n",
       " world12d_2    (0.4, 0.5]\n",
       " world12d_3    (0.4, 0.5]\n",
       " world12d_4    (0.4, 0.5]\n",
       "                  ...    \n",
       " olive_65      (0.5, 0.6]\n",
       " olive_66      (0.5, 0.6]\n",
       " olive_67      (0.5, 0.6]\n",
       " olive_68      (0.4, 0.5]\n",
       " olive_69      (0.5, 0.6]\n",
       " Name: DTM_KL01, Length: 1310, dtype: category\n",
       " Categories (10, interval[float64]): [(-0.000999, 0.0999] < (0.0999, 0.2] < (0.2, 0.3] < (0.3, 0.4] ... (0.6, 0.699] < (0.699, 0.799] < (0.799, 0.899] < (0.899, 0.999]],\n",
       " array([-0.00099927,  0.09992748,  0.19985497,  0.29978245,  0.39970993,\n",
       "         0.49963741,  0.5995649 ,  0.69949238,  0.79941986,  0.89934735,\n",
       "         0.99927483]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(pval['DTM_KL01'], bins=10, retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.2815515655446004,\n",
       " -0.8416212335729142,\n",
       " -0.5244005127080407,\n",
       " -0.2533471031357997,\n",
       " 0.0,\n",
       " 0.25334710313580006,\n",
       " 0.524400512708041,\n",
       " 0.8416212335729143,\n",
       " 1.2815515655446004]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = []\n",
    "for i in range(1, 10):\n",
    "    ranges.append(stats.norm.ppf(0.1 * i))\n",
    "\n",
    "ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_size = {\n",
    "\"boston\": 70,\n",
    "\"breastcancercoimbra\": 70,\n",
    "\"breastcancerwisconsinprognostic\": 70,\n",
    "\"covertype\": 65,\n",
    "\"dermatology\": 70, #XX\n",
    "\"drybean\": 65,\n",
    "\"echocardiogram\": 70,\n",
    "\"ecoli\": 70,\n",
    "\"extyaleb\": 70,\n",
    "\"glassidentification\": 70,\n",
    "\"heartdisease\": 70,\n",
    "\"hepatitis\": 65,\n",
    "\"housing\": 65,\n",
    "\"iris\": 70,\n",
    "\"mnist64\": 70,\n",
    "\"olive\": 70,  ##X\n",
    "\"weather\": 70, \n",
    "\"wine\": 70, \n",
    "\"world12d\": 70\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_json('./metric_all.json', orient='index')\n",
    "s = pd.read_json('./scag_all.json', orient='index')\n",
    "sm = pd.merge(s, m, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = {}\n",
    "for col in sm.columns:\n",
    "    median[col] = sm[col].median()\n",
    "\n",
    "for i, row in sm.iterrows():\n",
    "    for col in row.index:\n",
    "        if row[col] > median[col]:\n",
    "            sm.loc[i, col] = True\n",
    "        else:\n",
    "            sm.loc[i, col] = False\n",
    "\n",
    "s_bool = s\n",
    "\n",
    "for i, row in s_bool.iterrows():\n",
    "    for col in row.index:\n",
    "        if row[col] > median[col]:\n",
    "            s_bool.loc[i, col] = True\n",
    "        else:\n",
    "            s_bool.loc[i, col] = False\n",
    "m_bool = m\n",
    "\n",
    "for i, row in m_bool.iterrows():\n",
    "    for col in row.index:\n",
    "        if row[col] > median[col]:\n",
    "            m_bool.loc[i, col] = True\n",
    "        else:\n",
    "            m_bool.loc[i, col] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.drop(['stringy', 'DTM_KL1','DTM_KL001','Spearman', 'Continuity', 'Cohesiveness'], axis=1, inplace=True)\n",
    "dataset = [True, False]\n",
    "\n",
    "printList = list(product(dataset, repeat = len(sm.columns)))\n",
    "\n",
    "x = {}\n",
    "for i in printList:\n",
    "    x[i] = []\n",
    "\n",
    "for i in sm.columns:\n",
    "    print(i, end=',')\n",
    "print('mdp')\n",
    "\n",
    "for i, row in sm.iterrows():\n",
    "    x[tuple(row.values)].append(row.name)\n",
    "for i in x:\n",
    "    for ii in i:\n",
    "        print(ii, end=',')\n",
    "    for ii in x[i]:\n",
    "        print(ii, end='/')\n",
    "    print(',', end='')\n",
    "    print(len(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlying,convex,skinny,skewed,clumpy,striated,sparse,mdp\n"
     ]
    }
   ],
   "source": [
    "s_bool.drop(['stringy', 'monotonic'], axis=1, inplace=True)\n",
    "\n",
    "dataset = [True, False]\n",
    "\n",
    "printList = list(product(dataset, repeat = len(s_bool.columns)))\n",
    "\n",
    "x = {}\n",
    "for i in printList:\n",
    "    x[i] = []\n",
    "\n",
    "for i in s_bool.columns:\n",
    "    print(i, end=',')\n",
    "print('mdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in s_bool.iterrows():\n",
    "    x[tuple(row.values)].append(row.name)\n",
    "for i in x:\n",
    "    for ii in i:\n",
    "        print(ii, end=',')\n",
    "    for ii in x[i]:\n",
    "        print(ii, end='/')\n",
    "    print(',', end='')\n",
    "    print(len(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, DTM_KL01, Sammon, Trustworthiness, Steadiness, mdp\n"
     ]
    }
   ],
   "source": [
    "m_bool.drop(['DTM_KL1','DTM_KL001','Spearman', 'Continuity', 'Cohesiveness'], axis=1, inplace=True)\n",
    "\n",
    "dataset = [True, False]\n",
    "\n",
    "\n",
    "printList = list(product(dataset, repeat = len(m_bool.columns)))\n",
    "\n",
    "x = {}\n",
    "for i in printList:\n",
    "    x[i] = []\n",
    "\n",
    "for i in m_bool.columns:\n",
    "    print(i, end=',')\n",
    "print('mdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m = pd.read_csv('./metric_bin.csv', index_col=[0, 1, 2, 3, 4],keep_default_na=False)\n",
    "df_s = pd.read_csv('./scag_bin.csv', index_col=[0, 1, 2, 3, 4, 5, 6],keep_default_na=False)\n",
    "# df_sm = pd.read_csv('./all_bin.csv', index_col=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_result_m = {}\n",
    "for i , row in df_m.sort_values(by=['cnt'],ascending=False).iterrows():\n",
    "    mdps = row.mdp.split('/') \n",
    "    charts = []\n",
    "    for mdp in mdps:\n",
    "        if (len(mdp.split('_')) < 2):\n",
    "            continue\n",
    "        dataset = mdp.split('_')[0]\n",
    "        numProj = mdp.split('_')[1]\n",
    "        xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "        xy.columns = ['x', 'y']\n",
    "        label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "        label.columns = ['label']\n",
    "        data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "        with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                meta = json.load(f)\n",
    "        \n",
    "        c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'{dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "        charts.append(c)\n",
    "    title0 = \"1:\"\n",
    "    title1 = \"0:\"\n",
    "    for idx in range(len(i)):\n",
    "        sc = df_m.index.names[idx]\n",
    "        x = i[idx]\n",
    "        if (x):\n",
    "            title0 += sc + ', '\n",
    "        else:\n",
    "            title1 += sc + ', '\n",
    "    title = title0 + ' / ' + title1\n",
    "    num_per_row = 10\n",
    "    x = []\n",
    "    for ii in range(int(len(mdps) / num_per_row)):\n",
    "            x.append(alt.hconcat(*charts[ii*num_per_row:(ii+1)*num_per_row], spacing=3))\n",
    "    xx = alt.vconcat(*x).properties(title=alt.TitleParams(text=title, anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "    binned_result_m[(tuple(i))] = xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxx = 10\n",
    "list(binned_result_m.values())[idxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2076d717d0b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned_result_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idxx = 0\n",
    "list(binned_result_s.values())[idxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143, 139,  47,  43,  36,  34,  33,  33,  32,  31,  27,  27,  26,\n",
       "        26,  23,  21,  19,  19,  18,  18,  18,  17,  16,  14,  14,  14,\n",
       "        14,  13,  13,  12,  12,  12,  11,  11,  11,  11,  11,  10,  10,\n",
       "         9,   9,   9,   9,   9,   8,   8,   8,   8,   8,   8,   8,   7,\n",
       "         6,   6,   6,   6,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "         5,   4,   4,   4,   4,   4,   4,   4,   4,   4,   3,   3,   3,\n",
       "         3,   3,   3,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.sort_values(by=['cnt'], ascending=False).cnt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_result_s = {}\n",
    "for i , row in df_s.sort_values(by=['cnt'],ascending=False).iterrows():\n",
    "    mdps = row.mdp.split('/') \n",
    "    charts = []\n",
    "    for mdp in mdps:\n",
    "        if (len(mdp.split('_')) < 2):\n",
    "            continue\n",
    "        dataset = mdp.split('_')[0]\n",
    "        numProj = mdp.split('_')[1]\n",
    "        xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "        xy.columns = ['x', 'y']\n",
    "        label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "        label.columns = ['label']\n",
    "        data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "        with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                meta = json.load(f)\n",
    "        \n",
    "        c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'{dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "        charts.append(c)\n",
    "    title0 = \"1:\"\n",
    "    title1 = \"0:\"\n",
    "    for idx in range(len(i)):\n",
    "        sc = df_s.index.names[idx]\n",
    "        x = i[idx]\n",
    "        if (x):\n",
    "            title0 += sc + ', '\n",
    "        else:\n",
    "            title1 += sc + ', '\n",
    "    title = title0 + ' / ' + title1\n",
    "    num_per_row = 10\n",
    "    x = []\n",
    "    for ii in range(int(len(mdps) / num_per_row)):\n",
    "            x.append(alt.hconcat(*charts[ii*num_per_row:(ii+1)*num_per_row], spacing=3))\n",
    "    xx = alt.vconcat(*x).properties(title=alt.TitleParams(text=title, anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "    binned_result_s[(tuple(i))] = xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_result_sm = {}\n",
    "for i , row in df_sm.sort_values(by=['cnt'],ascending=False).iterrows():\n",
    "    mdps = row.mdp.split('/') \n",
    "    charts = []\n",
    "    for mdp in mdps:\n",
    "        if (len(mdp.split('_')) < 2):\n",
    "            continue\n",
    "        dataset = mdp.split('_')[0]\n",
    "        numProj = mdp.split('_')[1]\n",
    "        xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "        xy.columns = ['x', 'y']\n",
    "        label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "        label.columns = ['label']\n",
    "        data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "        with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                meta = json.load(f)\n",
    "        \n",
    "        c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'{dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "        charts.append(c)\n",
    "    title0 = \"1:\"\n",
    "    title1 = \"0:\"\n",
    "    for idx in range(len(i)):\n",
    "        sc = df_sm.index.names[idx]\n",
    "        x = i[idx]\n",
    "        if (x):\n",
    "            title0 += sc + ', '\n",
    "        else:\n",
    "            title1 += sc + ', '\n",
    "    title = title0 + ' / ' + title1\n",
    "    num_per_row = 10\n",
    "    x = []\n",
    "    for ii in range(int(len(mdps) / num_per_row)):\n",
    "            x.append(alt.hconcat(*charts[ii*num_per_row:(ii+1)*num_per_row], spacing=3))\n",
    "    xx = alt.vconcat(*x).properties(title=alt.TitleParams(text=title, anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "    binned_result_sm[(tuple(i))] = xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binned_result_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-105e3c94d273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned_result_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'binned_result_s' is not defined"
     ]
    }
   ],
   "source": [
    "list(binned_result_s.values())[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in m_bool.iterrows():\n",
    "    x[tuple(row.values)].append(row.name)\n",
    "res = 0\n",
    "for i in x:\n",
    "    for ii in i:\n",
    "        print(ii, end=',')\n",
    "    for ii in x[i]:\n",
    "        print(ii, end='/')\n",
    "    print(',', end='')\n",
    "    print(len(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scagnostics = ['outlying', 'convex', 'skinny', 'stringy', 'monotonic', 'skewed',\n",
    "       'clumpy', 'striated', 'sparse']\n",
    "# scagnostics = ['sparse']\n",
    "scags = {}\n",
    "num_per_scag = 100\n",
    "num_per_row = 10\n",
    "for scag in scagnostics:\n",
    "       high = s.sort_values(by=[scag], ascending=False).index[:num_per_scag]\n",
    "       charts_high = []\n",
    "       for x in high:\n",
    "              dataset = x.split('_')[0]\n",
    "              numProj = x.split('_')[1]\n",
    "              xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "              xy.columns = ['x', 'y']\n",
    "              label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "              label.columns = ['label']\n",
    "              data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "              with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                     meta = json.load(f)\n",
    "              c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'({round(s.loc[x][scag], 2)}) {dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "              charts_high.append(c)\n",
    "       x = []\n",
    "       for i in range(int(num_per_scag / num_per_row)):\n",
    "              x.append(alt.hconcat(*charts_high[i*num_per_row:(i+1)*num_per_row], spacing=3))\n",
    "       \n",
    "       alt_high = alt.vconcat(*x).properties(title=alt.TitleParams(text=scag+\" High 100\", anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "       \n",
    "       low = s.sort_values(by=[scag], ascending=True).index[:num_per_scag]\n",
    "       charts_low = []\n",
    "       for x in low:\n",
    "              dataset = x.split('_')[0]\n",
    "              numProj = x.split('_')[1]\n",
    "              xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "              xy.columns = ['x', 'y']\n",
    "              label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "              label.columns = ['label']\n",
    "              data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "              with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                     meta = json.load(f)\n",
    "              c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'({round(s.loc[x][scag], 2)}) {dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "              charts_low.append(c)\n",
    "       x = []\n",
    "       for i in range(int(num_per_scag / num_per_row)):\n",
    "              x.append(alt.hconcat(*charts_low[i*num_per_row:(i+1)*num_per_row], spacing=3))\n",
    "       \n",
    "       alt_low = alt.vconcat(*x).properties(title=alt.TitleParams(text=scag+\" low 100\", anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "       scags[scag] = (alt_high & alt_low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in scagnostics:\n",
    "    print(f'<li><a href=\"./metric_viewer/scagpage/scag_{s}.html\"><span style=\"color:#888\">{s}</span></a></li>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scagnostics = ['outlying', 'convex', 'skinny', 'stringy', 'monotonic', 'skewed',\n",
    "#        'clumpy', 'striated'. 'sparse']\n",
    "idx = 7\n",
    "for i in range(len(scagnostics)):\n",
    "    scags[scagnostics[i]].save(f'./scag_{scagnostics[i]}.html')\n",
    "# scags[scagnostics[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = []\n",
    "for x in a:\n",
    "    dataset = x.split('_')[0]\n",
    "    numProj = x.split('_')[1]\n",
    "    xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "    xy.columns = ['x', 'y']\n",
    "    label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "    label.columns = ['label']\n",
    "    data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "    with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "        meta = json.load(f)\n",
    "    c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_point().encode(\n",
    "        x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "        y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "        color=alt.Color('label:N', legend=None)\n",
    "    ).properties(width=150, height=150, title=f'{dataset}-{numProj}, {meta[\"method\"]}')\n",
    "    charts.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = []\n",
    "for i in range(int(30 / 5)):\n",
    "    x.append(alt.hconcat(*charts[i*5:(i+1)*5]))\n",
    "    \n",
    "alt.vconcat(*x).properties(title=alt.TitleParams(text=, anchor='middle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_type = [\n",
    "    'DTM_KL1',\n",
    "    'DTM_KL01',\n",
    "    'DTM_KL001',\n",
    "    'RMSE',\n",
    "    'Sammon',\n",
    "    'Spearman',\n",
    "    'Trustworthiness',\n",
    "    'Continuity',\n",
    "    'Steadiness',\n",
    "    'Cohesiveness'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = {}\n",
    "scaled_data = {}\n",
    "raw = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    boston = pd.read_csv(f'./metric_raw/{dataset}_metrics.csv', index_col='num')\n",
    "    raw[dataset] = boston\n",
    "\n",
    "    method = boston[\"method\"]\n",
    "    boston.drop(['method'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    scaled  = StandardScaler().fit_transform(boston)\n",
    "\n",
    "    normalized = preprocessing.normalize(boston, axis=0)\n",
    "    np_normalized = np.array(normalized)\n",
    "    \n",
    "    boston[\"method\"] = method\n",
    "    kmeans_result = KMeans(n_clusters=10).fit(np_normalized).predict(np_normalized)\n",
    "    hdbscan_result = hdbscan.HDBSCAN(min_cluster_size=3).fit_predict(np_normalized)\n",
    "    normalized_data[dataset] = np_normalized\n",
    "    scaled_data[dataset] = scaled\n",
    "    boston[\"cluster_kmeans\"] = kmeans_result\n",
    "    boston[\"cluster_hdbscan\"] = hdbscan_result\n",
    "    cluster_kmeans = {}\n",
    "    cluster_hdbscan = {}\n",
    "    for idx, data in boston.groupby('cluster_kmeans'):\n",
    "        cluster_kmeans[idx] = data.index.tolist()\n",
    "\n",
    "    for idx, data in boston.groupby('cluster_hdbscan'):\n",
    "        cluster_hdbscan[idx] = data.index.tolist()\n",
    "\n",
    "    # with open(f'hdbscan/clustering_{dataset}.json', 'w') as f:\n",
    "    #     json.dump(cluster_hdbscan, f)\n",
    "\n",
    "    # with open(f'kmeans/clustering_{dataset}.json', 'w') as f:\n",
    "    #     json.dump(cluster_kmeans, f)\n",
    "\n",
    "    # boston.to_json(f'./metric/{dataset}_metrics.json', orient='index')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=3, min_dist=0.1, n_components=2)\n",
    "\n",
    "for dataset in datasets[:1]:\n",
    "    res_n = reducer.fit_transform(normalized_data[dataset])\n",
    "    res_s = reducer.fit_transform(scaled_data[dataset])\n",
    "\n",
    "    res_n = pd.DataFrame(res_n)\n",
    "    res_s = pd.DataFrame(res_s)\n",
    "\n",
    "    res_n.columns = ['x', 'y']\n",
    "    res_s.columns = ['x', 'y']\n",
    "    res_n.index.name = 'num'\n",
    "    res_s.index.name = 'num'\n",
    "\n",
    "    raw_d = raw[dataset]\n",
    "    res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "    res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "    charts = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "    ).properties(title=dataset+' normalized', width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "        ).properties(title=dataset+' standard', width=200, height=200)\n",
    "\n",
    "\n",
    "for dataset in datasets[1:]:\n",
    "    res_n = reducer.fit_transform(normalized_data[dataset])\n",
    "    res_s = reducer.fit_transform(scaled_data[dataset])\n",
    "\n",
    "    res_n = pd.DataFrame(res_n)\n",
    "    res_s = pd.DataFrame(res_s)\n",
    "\n",
    "    res_n.columns = ['x', 'y']\n",
    "    res_s.columns = ['x', 'y']\n",
    "    res_n.index.name = 'num'\n",
    "    res_s.index.name = 'num'\n",
    "\n",
    "    raw_d = raw[dataset]\n",
    "    res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "    res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "    res_chart = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "    ).properties(title=dataset+' normalized', width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "        ).properties(title=dataset+' standard', width=200, height=200)\n",
    "\n",
    "    charts &= res_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts.title = 'UMAP(n_neighbors = 3, min_dist = 0.1, n_components=2)'\n",
    "charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartss={}\n",
    "for dataset in datasets[1:]:\n",
    "    perplexity = 5\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "\n",
    "    res_n = tsne.fit_transform(normalized_data[dataset])\n",
    "    res_s = tsne.fit_transform(scaled_data[dataset])\n",
    "\n",
    "    res_n = pd.DataFrame(res_n)\n",
    "    res_s = pd.DataFrame(res_s)\n",
    "\n",
    "    res_n.columns = ['x', 'y']\n",
    "    res_s.columns = ['x', 'y']\n",
    "    res_n.index.name = 'num'\n",
    "    res_s.index.name = 'num'\n",
    "\n",
    "    raw_d = raw[dataset]\n",
    "    res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "    res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "    charts = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "    ).properties(title='n /  perplexity : '+ str(perplexity), width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "        ).properties(title='s /perplexity : '+ str(perplexity), width=200, height=200)\n",
    "\n",
    "    for perplexity in [10, 15, 20, 30, 40, 50]:\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "\n",
    "        res_n = tsne.fit_transform(normalized_data[dataset])\n",
    "        res_s = tsne.fit_transform(scaled_data[dataset])\n",
    "\n",
    "        res_n = pd.DataFrame(res_n)\n",
    "        res_s = pd.DataFrame(res_s)\n",
    "\n",
    "        res_n.columns = ['x', 'y']\n",
    "        res_s.columns = ['x', 'y']\n",
    "        res_n.index.name = 'num'\n",
    "        res_s.index.name = 'num'\n",
    "\n",
    "        raw_d = raw[dataset]\n",
    "        res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "        res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "        res_chart = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "            x='x',\n",
    "            y='y',\n",
    "            color='method',\n",
    "        ).properties(title='perplexity : '+ str(perplexity), width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "            x='x',\n",
    "            y='y',\n",
    "            color='method',\n",
    "            ).properties(title='perplexity : '+ str(perplexity), width=200, height=200)\n",
    "\n",
    "        charts &= res_chart\n",
    "\n",
    "    charts.title = 't-SNE /' + dataset\n",
    "    chartss[dataset] = charts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for dataset in datasets[1:]:\n",
    "#     res_n = tsne.fit_transform(normalized_data[dataset])\n",
    "#     res_s = tsne.fit_transform(scaled_data[dataset])\n",
    "\n",
    "#     res_n = pd.DataFrame(res_n)\n",
    "#     res_s = pd.DataFrame(res_s)\n",
    "\n",
    "#     res_n.columns = ['x', 'y']\n",
    "#     res_s.columns = ['x', 'y']\n",
    "#     res_n.index.name = 'num'\n",
    "#     res_s.index.name = 'num'\n",
    "\n",
    "#     raw_d = raw[dataset]\n",
    "#     res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "#     res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "#     res_chart = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "#         x='x',\n",
    "#         y='y',\n",
    "#         color='method',\n",
    "#     ).properties(title=dataset+' normalized', width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "#         x='x',\n",
    "#         y='y',\n",
    "#         color='method',\n",
    "#         ).properties(title=dataset+' standard', width=200, height=200)\n",
    "\n",
    "#     charts &= res_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "279752607fe7bb0c2dfae522ee6cf570829a8cbd0e714b220bc1a96a73cd6955"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
