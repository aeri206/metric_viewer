{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "import hdbscan\n",
    "\n",
    "import umap\n",
    "\n",
    "from  itertools import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'boston', \n",
    "    'breastcancercoimbra',\n",
    "    'breastcancerwisconsinprognostic',\n",
    "    'covertype',\n",
    "    'dermatology',\n",
    "    'drybean',\n",
    "    'echocardiogram',\n",
    "    'ecoli',\n",
    "    'extyaleb',\n",
    "    'glassidentification',\n",
    "    'heartdisease',\n",
    "    'hepatitis',\n",
    "    'housing', 'iris', 'mnist64', 'olive', 'weather', 'wine', 'world12d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_size = {\n",
    "\"boston\": 70,\n",
    "\"breastcancercoimbra\": 70,\n",
    "\"breastcancerwisconsinprognostic\": 70,\n",
    "\"covertype\": 65,\n",
    "\"dermatology\": 70, #XX\n",
    "\"drybean\": 65,\n",
    "\"echocardiogram\": 70,\n",
    "\"ecoli\": 70,\n",
    "\"extyaleb\": 70,\n",
    "\"glassidentification\": 70,\n",
    "\"heartdisease\": 70,\n",
    "\"hepatitis\": 65,\n",
    "\"housing\": 65,\n",
    "\"iris\": 70,\n",
    "\"mnist64\": 70,\n",
    "\"olive\": 70,  ##X\n",
    "\"weather\": 70, \n",
    "\"wine\": 70, \n",
    "\"world12d\": 70\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a4674b40504e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_json('./metric_all.json', orient='index')\n",
    "s = pd.read_json('./scag_all.json', orient='index')\n",
    "sm = pd.merge(s, m, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = {}\n",
    "for col in sm.columns:\n",
    "    median[col] = sm[col].median()\n",
    "\n",
    "for i, row in sm.iterrows():\n",
    "    for col in row.index:\n",
    "        if row[col] > median[col]:\n",
    "            sm.loc[i, col] = True\n",
    "        else:\n",
    "            sm.loc[i, col] = False\n",
    "\n",
    "s_bool = s\n",
    "\n",
    "for i, row in s_bool.iterrows():\n",
    "    for col in row.index:\n",
    "        if row[col] > median[col]:\n",
    "            s_bool.loc[i, col] = True\n",
    "        else:\n",
    "            s_bool.loc[i, col] = False\n",
    "m_bool = m\n",
    "\n",
    "for i, row in m_bool.iterrows():\n",
    "    for col in row.index:\n",
    "        if row[col] > median[col]:\n",
    "            m_bool.loc[i, col] = True\n",
    "        else:\n",
    "            m_bool.loc[i, col] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.drop(['stringy', 'DTM_KL1','DTM_KL001','Spearman', 'Continuity', 'Cohesiveness'], axis=1, inplace=True)\n",
    "dataset = [True, False]\n",
    "\n",
    "printList = list(product(dataset, repeat = len(sm.columns)))\n",
    "\n",
    "x = {}\n",
    "for i in printList:\n",
    "    x[i] = []\n",
    "\n",
    "for i in sm.columns:\n",
    "    print(i, end=',')\n",
    "print('mdp')\n",
    "\n",
    "for i, row in sm.iterrows():\n",
    "    x[tuple(row.values)].append(row.name)\n",
    "for i in x:\n",
    "    for ii in i:\n",
    "        print(ii, end=',')\n",
    "    for ii in x[i]:\n",
    "        print(ii, end='/')\n",
    "    print(',', end='')\n",
    "    print(len(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlying,convex,skinny,skewed,clumpy,striated,sparse,mdp\n"
     ]
    }
   ],
   "source": [
    "s_bool.drop(['stringy', 'monotonic'], axis=1, inplace=True)\n",
    "\n",
    "dataset = [True, False]\n",
    "\n",
    "printList = list(product(dataset, repeat = len(s_bool.columns)))\n",
    "\n",
    "x = {}\n",
    "for i in printList:\n",
    "    x[i] = []\n",
    "\n",
    "for i in s_bool.columns:\n",
    "    print(i, end=',')\n",
    "print('mdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in s_bool.iterrows():\n",
    "    x[tuple(row.values)].append(row.name)\n",
    "for i in x:\n",
    "    for ii in i:\n",
    "        print(ii, end=',')\n",
    "    for ii in x[i]:\n",
    "        print(ii, end='/')\n",
    "    print(',', end='')\n",
    "    print(len(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, DTM_KL01, Sammon, Trustworthiness, Steadiness, mdp\n"
     ]
    }
   ],
   "source": [
    "m_bool.drop(['DTM_KL1','DTM_KL001','Spearman', 'Continuity', 'Cohesiveness'], axis=1, inplace=True)\n",
    "\n",
    "dataset = [True, False]\n",
    "\n",
    "\n",
    "printList = list(product(dataset, repeat = len(m_bool.columns)))\n",
    "\n",
    "x = {}\n",
    "for i in printList:\n",
    "    x[i] = []\n",
    "\n",
    "for i in m_bool.columns:\n",
    "    print(i, end=',')\n",
    "print('mdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_m = pd.read_csv('./metric_bin.csv', index_col=[0, 1, 2, 3, 4],keep_default_na=False)\n",
    "df_s = pd.read_csv('./scag_bin.csv', index_col=[0, 1, 2, 3, 4, 5, 6],keep_default_na=False)\n",
    "# df_sm = pd.read_csv('./all_bin.csv', index_col=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_result_m = {}\n",
    "for i , row in df_m.sort_values(by=['cnt'],ascending=False).iterrows():\n",
    "    mdps = row.mdp.split('/') \n",
    "    charts = []\n",
    "    for mdp in mdps:\n",
    "        if (len(mdp.split('_')) < 2):\n",
    "            continue\n",
    "        dataset = mdp.split('_')[0]\n",
    "        numProj = mdp.split('_')[1]\n",
    "        xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "        xy.columns = ['x', 'y']\n",
    "        label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "        label.columns = ['label']\n",
    "        data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "        with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                meta = json.load(f)\n",
    "        \n",
    "        c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'{dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "        charts.append(c)\n",
    "    title0 = \"1:\"\n",
    "    title1 = \"0:\"\n",
    "    for idx in range(len(i)):\n",
    "        sc = df_m.index.names[idx]\n",
    "        x = i[idx]\n",
    "        if (x):\n",
    "            title0 += sc + ', '\n",
    "        else:\n",
    "            title1 += sc + ', '\n",
    "    title = title0 + ' / ' + title1\n",
    "    num_per_row = 10\n",
    "    x = []\n",
    "    for ii in range(int(len(mdps) / num_per_row)):\n",
    "            x.append(alt.hconcat(*charts[ii*num_per_row:(ii+1)*num_per_row], spacing=3))\n",
    "    xx = alt.vconcat(*x).properties(title=alt.TitleParams(text=title, anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "    binned_result_m[(tuple(i))] = xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxx = 10\n",
    "list(binned_result_m.values())[idxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2076d717d0b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned_result_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idxx = 0\n",
    "list(binned_result_s.values())[idxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143, 139,  47,  43,  36,  34,  33,  33,  32,  31,  27,  27,  26,\n",
       "        26,  23,  21,  19,  19,  18,  18,  18,  17,  16,  14,  14,  14,\n",
       "        14,  13,  13,  12,  12,  12,  11,  11,  11,  11,  11,  10,  10,\n",
       "         9,   9,   9,   9,   9,   8,   8,   8,   8,   8,   8,   8,   7,\n",
       "         6,   6,   6,   6,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "         5,   4,   4,   4,   4,   4,   4,   4,   4,   4,   3,   3,   3,\n",
       "         3,   3,   3,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.sort_values(by=['cnt'], ascending=False).cnt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_result_s = {}\n",
    "for i , row in df_s.sort_values(by=['cnt'],ascending=False).iterrows():\n",
    "    mdps = row.mdp.split('/') \n",
    "    charts = []\n",
    "    for mdp in mdps:\n",
    "        if (len(mdp.split('_')) < 2):\n",
    "            continue\n",
    "        dataset = mdp.split('_')[0]\n",
    "        numProj = mdp.split('_')[1]\n",
    "        xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "        xy.columns = ['x', 'y']\n",
    "        label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "        label.columns = ['label']\n",
    "        data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "        with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                meta = json.load(f)\n",
    "        \n",
    "        c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'{dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "        charts.append(c)\n",
    "    title0 = \"1:\"\n",
    "    title1 = \"0:\"\n",
    "    for idx in range(len(i)):\n",
    "        sc = df_s.index.names[idx]\n",
    "        x = i[idx]\n",
    "        if (x):\n",
    "            title0 += sc + ', '\n",
    "        else:\n",
    "            title1 += sc + ', '\n",
    "    title = title0 + ' / ' + title1\n",
    "    num_per_row = 10\n",
    "    x = []\n",
    "    for ii in range(int(len(mdps) / num_per_row)):\n",
    "            x.append(alt.hconcat(*charts[ii*num_per_row:(ii+1)*num_per_row], spacing=3))\n",
    "    xx = alt.vconcat(*x).properties(title=alt.TitleParams(text=title, anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "    binned_result_s[(tuple(i))] = xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_result_sm = {}\n",
    "for i , row in df_sm.sort_values(by=['cnt'],ascending=False).iterrows():\n",
    "    mdps = row.mdp.split('/') \n",
    "    charts = []\n",
    "    for mdp in mdps:\n",
    "        if (len(mdp.split('_')) < 2):\n",
    "            continue\n",
    "        dataset = mdp.split('_')[0]\n",
    "        numProj = mdp.split('_')[1]\n",
    "        xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "        xy.columns = ['x', 'y']\n",
    "        label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "        label.columns = ['label']\n",
    "        data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "        with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                meta = json.load(f)\n",
    "        \n",
    "        c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'{dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "        charts.append(c)\n",
    "    title0 = \"1:\"\n",
    "    title1 = \"0:\"\n",
    "    for idx in range(len(i)):\n",
    "        sc = df_sm.index.names[idx]\n",
    "        x = i[idx]\n",
    "        if (x):\n",
    "            title0 += sc + ', '\n",
    "        else:\n",
    "            title1 += sc + ', '\n",
    "    title = title0 + ' / ' + title1\n",
    "    num_per_row = 10\n",
    "    x = []\n",
    "    for ii in range(int(len(mdps) / num_per_row)):\n",
    "            x.append(alt.hconcat(*charts[ii*num_per_row:(ii+1)*num_per_row], spacing=3))\n",
    "    xx = alt.vconcat(*x).properties(title=alt.TitleParams(text=title, anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "    binned_result_sm[(tuple(i))] = xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binned_result_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-105e3c94d273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned_result_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'binned_result_s' is not defined"
     ]
    }
   ],
   "source": [
    "list(binned_result_s.values())[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in m_bool.iterrows():\n",
    "    x[tuple(row.values)].append(row.name)\n",
    "res = 0\n",
    "for i in x:\n",
    "    for ii in i:\n",
    "        print(ii, end=',')\n",
    "    for ii in x[i]:\n",
    "        print(ii, end='/')\n",
    "    print(',', end='')\n",
    "    print(len(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scagnostics = ['outlying', 'convex', 'skinny', 'stringy', 'monotonic', 'skewed',\n",
    "       'clumpy', 'striated', 'sparse']\n",
    "# scagnostics = ['sparse']\n",
    "scags = {}\n",
    "num_per_scag = 100\n",
    "num_per_row = 10\n",
    "for scag in scagnostics:\n",
    "       high = s.sort_values(by=[scag], ascending=False).index[:num_per_scag]\n",
    "       charts_high = []\n",
    "       for x in high:\n",
    "              dataset = x.split('_')[0]\n",
    "              numProj = x.split('_')[1]\n",
    "              xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "              xy.columns = ['x', 'y']\n",
    "              label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "              label.columns = ['label']\n",
    "              data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "              with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                     meta = json.load(f)\n",
    "              c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'({round(s.loc[x][scag], 2)}) {dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "              charts_high.append(c)\n",
    "       x = []\n",
    "       for i in range(int(num_per_scag / num_per_row)):\n",
    "              x.append(alt.hconcat(*charts_high[i*num_per_row:(i+1)*num_per_row], spacing=3))\n",
    "       \n",
    "       alt_high = alt.vconcat(*x).properties(title=alt.TitleParams(text=scag+\" High 100\", anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "       \n",
    "       low = s.sort_values(by=[scag], ascending=True).index[:num_per_scag]\n",
    "       charts_low = []\n",
    "       for x in low:\n",
    "              dataset = x.split('_')[0]\n",
    "              numProj = x.split('_')[1]\n",
    "              xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "              xy.columns = ['x', 'y']\n",
    "              label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "              label.columns = ['label']\n",
    "              data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "              with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "                     meta = json.load(f)\n",
    "              c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_circle(opacity=.5, size=20).encode(\n",
    "                     x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "                     color=alt.Color('label:N', legend=None)\n",
    "              ).properties(width=150, height=150, title=alt.TitleParams(text=f'({round(s.loc[x][scag], 2)}) {dataset}-{numProj}, {meta[\"method\"]}', limit=150, fontSize=10))\n",
    "              charts_low.append(c)\n",
    "       x = []\n",
    "       for i in range(int(num_per_scag / num_per_row)):\n",
    "              x.append(alt.hconcat(*charts_low[i*num_per_row:(i+1)*num_per_row], spacing=3))\n",
    "       \n",
    "       alt_low = alt.vconcat(*x).properties(title=alt.TitleParams(text=scag+\" low 100\", anchor='middle', color='darkblue', fontSize=20), spacing=3)\n",
    "       scags[scag] = (alt_high & alt_low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in scagnostics:\n",
    "    print(f'<li><a href=\"./metric_viewer/scagpage/scag_{s}.html\"><span style=\"color:#888\">{s}</span></a></li>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scagnostics = ['outlying', 'convex', 'skinny', 'stringy', 'monotonic', 'skewed',\n",
    "#        'clumpy', 'striated'. 'sparse']\n",
    "idx = 7\n",
    "for i in range(len(scagnostics)):\n",
    "    scags[scagnostics[i]].save(f'./scag_{scagnostics[i]}.html')\n",
    "# scags[scagnostics[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = []\n",
    "for x in a:\n",
    "    dataset = x.split('_')[0]\n",
    "    numProj = x.split('_')[1]\n",
    "    xy = pd.read_json(f'./ld/{dataset}/ld_{str(numProj)}.json')\n",
    "    xy.columns = ['x', 'y']\n",
    "    label = pd.read_json(f'./ld/{dataset}/label.json')\n",
    "    label.columns = ['label']\n",
    "    data = pd.merge(xy, label, left_index=True, right_index=True)\n",
    "    with open(f'./ld/{dataset}/metadata_{str(numProj)}.json') as f:\n",
    "        meta = json.load(f)\n",
    "    c = alt.Chart(pd.merge(xy, label, left_index=True, right_index=True)).mark_point().encode(\n",
    "        x=alt.X('x', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "        y=alt.Y('y', title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "        color=alt.Color('label:N', legend=None)\n",
    "    ).properties(width=150, height=150, title=f'{dataset}-{numProj}, {meta[\"method\"]}')\n",
    "    charts.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = []\n",
    "for i in range(int(30 / 5)):\n",
    "    x.append(alt.hconcat(*charts[i*5:(i+1)*5]))\n",
    "    \n",
    "alt.vconcat(*x).properties(title=alt.TitleParams(text=, anchor='middle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_type = [\n",
    "    'DTM_KL1',\n",
    "    'DTM_KL01',\n",
    "    'DTM_KL001',\n",
    "    'RMSE',\n",
    "    'Sammon',\n",
    "    'Spearman',\n",
    "    'Trustworthiness',\n",
    "    'Continuity',\n",
    "    'Steadiness',\n",
    "    'Cohesiveness'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = {}\n",
    "scaled_data = {}\n",
    "raw = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    boston = pd.read_csv(f'./metric_raw/{dataset}_metrics.csv', index_col='num')\n",
    "    raw[dataset] = boston\n",
    "\n",
    "    method = boston[\"method\"]\n",
    "    boston.drop(['method'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    scaled  = StandardScaler().fit_transform(boston)\n",
    "\n",
    "    normalized = preprocessing.normalize(boston, axis=0)\n",
    "    np_normalized = np.array(normalized)\n",
    "    \n",
    "    boston[\"method\"] = method\n",
    "    kmeans_result = KMeans(n_clusters=10).fit(np_normalized).predict(np_normalized)\n",
    "    hdbscan_result = hdbscan.HDBSCAN(min_cluster_size=3).fit_predict(np_normalized)\n",
    "    normalized_data[dataset] = np_normalized\n",
    "    scaled_data[dataset] = scaled\n",
    "    boston[\"cluster_kmeans\"] = kmeans_result\n",
    "    boston[\"cluster_hdbscan\"] = hdbscan_result\n",
    "    cluster_kmeans = {}\n",
    "    cluster_hdbscan = {}\n",
    "    for idx, data in boston.groupby('cluster_kmeans'):\n",
    "        cluster_kmeans[idx] = data.index.tolist()\n",
    "\n",
    "    for idx, data in boston.groupby('cluster_hdbscan'):\n",
    "        cluster_hdbscan[idx] = data.index.tolist()\n",
    "\n",
    "    # with open(f'hdbscan/clustering_{dataset}.json', 'w') as f:\n",
    "    #     json.dump(cluster_hdbscan, f)\n",
    "\n",
    "    # with open(f'kmeans/clustering_{dataset}.json', 'w') as f:\n",
    "    #     json.dump(cluster_kmeans, f)\n",
    "\n",
    "    # boston.to_json(f'./metric/{dataset}_metrics.json', orient='index')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=3, min_dist=0.1, n_components=2)\n",
    "\n",
    "for dataset in datasets[:1]:\n",
    "    res_n = reducer.fit_transform(normalized_data[dataset])\n",
    "    res_s = reducer.fit_transform(scaled_data[dataset])\n",
    "\n",
    "    res_n = pd.DataFrame(res_n)\n",
    "    res_s = pd.DataFrame(res_s)\n",
    "\n",
    "    res_n.columns = ['x', 'y']\n",
    "    res_s.columns = ['x', 'y']\n",
    "    res_n.index.name = 'num'\n",
    "    res_s.index.name = 'num'\n",
    "\n",
    "    raw_d = raw[dataset]\n",
    "    res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "    res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "    charts = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "    ).properties(title=dataset+' normalized', width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "        ).properties(title=dataset+' standard', width=200, height=200)\n",
    "\n",
    "\n",
    "for dataset in datasets[1:]:\n",
    "    res_n = reducer.fit_transform(normalized_data[dataset])\n",
    "    res_s = reducer.fit_transform(scaled_data[dataset])\n",
    "\n",
    "    res_n = pd.DataFrame(res_n)\n",
    "    res_s = pd.DataFrame(res_s)\n",
    "\n",
    "    res_n.columns = ['x', 'y']\n",
    "    res_s.columns = ['x', 'y']\n",
    "    res_n.index.name = 'num'\n",
    "    res_s.index.name = 'num'\n",
    "\n",
    "    raw_d = raw[dataset]\n",
    "    res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "    res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "    res_chart = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "    ).properties(title=dataset+' normalized', width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "        ).properties(title=dataset+' standard', width=200, height=200)\n",
    "\n",
    "    charts &= res_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts.title = 'UMAP(n_neighbors = 3, min_dist = 0.1, n_components=2)'\n",
    "charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartss={}\n",
    "for dataset in datasets[1:]:\n",
    "    perplexity = 5\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "\n",
    "    res_n = tsne.fit_transform(normalized_data[dataset])\n",
    "    res_s = tsne.fit_transform(scaled_data[dataset])\n",
    "\n",
    "    res_n = pd.DataFrame(res_n)\n",
    "    res_s = pd.DataFrame(res_s)\n",
    "\n",
    "    res_n.columns = ['x', 'y']\n",
    "    res_s.columns = ['x', 'y']\n",
    "    res_n.index.name = 'num'\n",
    "    res_s.index.name = 'num'\n",
    "\n",
    "    raw_d = raw[dataset]\n",
    "    res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "    res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "    charts = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "    ).properties(title='n /  perplexity : '+ str(perplexity), width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='method',\n",
    "        ).properties(title='s /perplexity : '+ str(perplexity), width=200, height=200)\n",
    "\n",
    "    for perplexity in [10, 15, 20, 30, 40, 50]:\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "\n",
    "        res_n = tsne.fit_transform(normalized_data[dataset])\n",
    "        res_s = tsne.fit_transform(scaled_data[dataset])\n",
    "\n",
    "        res_n = pd.DataFrame(res_n)\n",
    "        res_s = pd.DataFrame(res_s)\n",
    "\n",
    "        res_n.columns = ['x', 'y']\n",
    "        res_s.columns = ['x', 'y']\n",
    "        res_n.index.name = 'num'\n",
    "        res_s.index.name = 'num'\n",
    "\n",
    "        raw_d = raw[dataset]\n",
    "        res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "        res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "        res_chart = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "            x='x',\n",
    "            y='y',\n",
    "            color='method',\n",
    "        ).properties(title='perplexity : '+ str(perplexity), width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "            x='x',\n",
    "            y='y',\n",
    "            color='method',\n",
    "            ).properties(title='perplexity : '+ str(perplexity), width=200, height=200)\n",
    "\n",
    "        charts &= res_chart\n",
    "\n",
    "    charts.title = 't-SNE /' + dataset\n",
    "    chartss[dataset] = charts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for dataset in datasets[1:]:\n",
    "#     res_n = tsne.fit_transform(normalized_data[dataset])\n",
    "#     res_s = tsne.fit_transform(scaled_data[dataset])\n",
    "\n",
    "#     res_n = pd.DataFrame(res_n)\n",
    "#     res_s = pd.DataFrame(res_s)\n",
    "\n",
    "#     res_n.columns = ['x', 'y']\n",
    "#     res_s.columns = ['x', 'y']\n",
    "#     res_n.index.name = 'num'\n",
    "#     res_s.index.name = 'num'\n",
    "\n",
    "#     raw_d = raw[dataset]\n",
    "#     res_n = raw_d.merge(res_n, left_index=True, right_index=True)\n",
    "#     res_s = raw_d.merge(res_s, left_index=True, right_index=True)\n",
    "\n",
    "#     res_chart = alt.Chart(res_n).mark_circle(size=10).encode(\n",
    "#         x='x',\n",
    "#         y='y',\n",
    "#         color='method',\n",
    "#     ).properties(title=dataset+' normalized', width=200, height=200) | alt.Chart(res_s).mark_circle(size=10).encode(\n",
    "#         x='x',\n",
    "#         y='y',\n",
    "#         color='method',\n",
    "#         ).properties(title=dataset+' standard', width=200, height=200)\n",
    "\n",
    "#     charts &= res_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "279752607fe7bb0c2dfae522ee6cf570829a8cbd0e714b220bc1a96a73cd6955"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
